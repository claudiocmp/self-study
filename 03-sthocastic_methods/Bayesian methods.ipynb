{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Statistics\n",
    "\n",
    "## Naive Bayes\n",
    "\n",
    "Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of features given the value of the class variable. Bayes’ theorem states the following relationship, given class variable y and dependent feature vector x1 through xn, :\n",
    "P(y∣x1,…,xn)=P(y)P(x1,…xn∣y) / P(x1,…,xn)\n",
    "Using the naive conditional independence assumption that\n",
    "P(xi|y,x1,…,xi−1,xi+1,…,xn)=P(xi|y),\n",
    "for all i, this relationship is simplified to\n",
    "P(y∣x1,…,xn)=P(y)∏i=1nP(xi∣y) / P(x1,…,xn)\n",
    "Since P(x1,…,xn) is constant given the input, we can use the following classification rule:\n",
    "P(y∣x1,…,xn)∝P(y)∏i=1nP(xi∣y)⇓y^=arg⁡maxyP(y)∏i=1nP(xi∣y),\n",
    "and we can use Maximum A Posteriori (MAP) estimation to estimate P(y) and P(xi∣y); the former is then the relative frequency of class y in the training set.\n",
    "\n",
    "## Empirical Bayes \n",
    "\n",
    "TODO \n",
    "\n",
    "## Estimation \n",
    "\n",
    "TODO\n",
    "\n",
    "## Prediction\n",
    "\n",
    "TODO\n",
    "\n",
    "# Bayesian Inference Techniques\n",
    "\n",
    "Multilevel models (also known as hierarchical linear models, nested data models, mixed models, random coefficient, random-effects models, random parameter models, or split-plot designs) are statistical models of parameters that vary at more than one level.[1] An example could be a model of student performance that contains measures for individual students as well as measures for classrooms within which the students are grouped. These models can be seen as generalizations of linear models(in particular, linear regression), although they can also extend to non-linear models. These models became much more popular after sufficient computing power and software became available.[1]\n",
    "\n",
    "## Gaussian processes (kriging)\n",
    "\n",
    "TODO\n",
    "\n",
    "## Kalman filters\n",
    "\n",
    "As an example application, consider the problem of determining the precise location of a truck. The truck can be equipped with a GPS unit that provides an estimate of the position within a few meters. The GPS estimate is likely to be noisy; readings 'jump around' rapidly, though remaining within a few meters of the real position. In addition, since the truck is expected to follow the laws of physics, its position can also be estimated by integrating its velocity over time, determined by keeping track of wheel revolutions and the angle of the steering wheel. This is a technique known as dead reckoning. Typically, the dead reckoning will provide a very smooth estimate of the truck's position, but it will drift over time as small errors accumulate.\n",
    "In this example, the Kalman filter can be thought of as operating in two distinct phases: predict and update. In the prediction phase, the truck's old position will be modified according to the physical laws of motion (the dynamic or \"state transition\" model). Not only will a new position estimate be calculated, but a new covariance will be calculated as well. Perhaps the covariance is proportional to the speed of the truck because we are more uncertain about the accuracy of the dead reckoning position estimate at high speeds but very certain about the position estimate when moving slowly. Next, in the update phase, a measurement of the truck's position is taken from the GPS unit. Along with this measurement comes some amount of uncertainty, and its covariance relative to that of the prediction from the previous phase determines how much the new measurement will affect the updated prediction. Ideally, as the dead reckoning estimates tend to drift away from the real position, the GPS measurement should pull the position estimate back towards the real position but not disturb it to the point of becoming rapidly jumping and noisy.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
